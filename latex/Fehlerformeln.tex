\subsection{Formeln für Fehlerrechnung und lineare Regression}
    \label{subsec:fehlerformeln}
        
    \underline{Mittelwert} (Bestwert, für den die quadratischen Abweichungen minimal werden): wird verwendet, 
    um verschiedene Werte für \textbf{dieselbe} gemessene Größe zu mitteln:
    
    \begin{equation}
        \bar{x}=\frac{1}{n} \overset{n}{\underset{i=1}{\sum}} x_i
        \label{eq:mittelwert}
    \end{equation}
    \\

    \underline{Gewichteter Mittelwert}: wird verwendet, um durch Mitteln der Ergebnisse mehrerer Messvorgänge, 
    abhängig von unterschiedlichen Variablen, eine Größe zu bestimmen:

    \begin{equation}
        \bar{x} = \frac{\underset{i}{\sum }\frac{x_i}{\sigma_i^2}}{\underset{i}{\sum }\frac{1}{\sigma_i^2}}
        \label{eq:gewichtetermittelwert}
    \end{equation}
    \\

    \underline{Fehler des gewichteten Mittelwertes}:

    \begin{equation}
        \sigma = \sqrt{\frac{1}{\underset{i}{\sum}\frac{1}{\sigma_i^2}}}
        \label{eq:fehlergewmi}
    \end{equation}
    \\

    \underline{Gesamtfehler}: der Gesamtfehler ist eine Möglichkeit, den statistischen und systematischen Fehler 
    in der Formel zu verbinden und auf einen Fehler zu berechnen; der systematische Fehler ist ein Fehler, der sich 
    beispielsweise durch eine falsche Messkalibrierung durch einen gesamten Versuch, auch bei Wiederholung desselben 
    Experimentes, durchzieht. Der statistische Fehler ist ein zufälliger Fehler, der durch ungenaues Ablesen oder 
    Zufälligkeiten im Versuchsaufbau entsteht:

    \begin{equation}
        \sigma_{ges} =\sqrt{\sigma_{sys}^2+\sigma_{stat}^2}
        \label{eq:Gesamtfehler}
    \end{equation}


    \underline{Fehlerfortpflanzung}: die zu berechnende Größe $f$ hängt von $N$ Größen $x_i$ ab, die alle
    Fehler $\sigma_{x_i}$ haben. Dann ist der Fehler der Funktion $f$ gegeben durch:

    \begin{equation}
        \sigma_f = \sqrt{\sum_{i=1}^{N}\left(\sigma_{x_i} \cdot \frac{\partial f}{\partial x_i}\right)^2}
        \label{eq:gaussfehlerfort}
    \end{equation}

\newpage

    \underline{Lineare Regression}: die Steigung m und der Achsenabschnitt b des linearen Fits werden $-$ wenn 
    benutzt $-$ durch ein Skript in Python berechnet:

    \begin{equation}
        m = \frac{n \sum x_i y_i - \sum x_i \sum y_i}{n \sum x_i^2 - (\sum x_i)^2}
        \label{eq:mlinregression}
    \end{equation}

    \begin{equation}
        b = \frac{\sum x_i^2 \sum y_i - \sum x_i \sum x_i y_i}{n \sum x_i^2 - (\sum x_i)^2}
        \label{eq:blinregression}
    \end{equation}
    \\

    \underline{Fehler für die Fitwerte der linearen Regression}:

    \begin{equation}
        \sigma_m^2 = \frac{n \sum (y_i - b - mx_i)^2}{(n-2)(n \sum x_i^2 - (\sum x_i)^2)}
        \label{eq:mlinregfehler}
    \end{equation}

    \begin{equation}
        \sigma_b^2 = \frac{\sum x_i^2 \sum (y_i - b - mx_i)^2}{(n-2)(n \sum x_i^2 -(\sum x_i)^2)}
        \label{eq:blinregfehler}
    \end{equation}